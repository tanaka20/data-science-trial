{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像認識：男女の判別"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "男女の画像から性別を判別するモデルを生成する。\n",
    "- 転移学習：VGG16モデルを使用し、最後尾の畳み込み３層の重みを更新\n",
    "- 生成したモデルをファイルに保存し、別途作成した顔検出プログラムにおいて性別判定に用いる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 13600,
     "status": "ok",
     "timestamp": 1602482059788,
     "user": {
      "displayName": "Yuki Tanaka",
      "photoUrl": "",
      "userId": "07563370713590614924"
     },
     "user_tz": -540
    },
    "id": "CU3x6uIiLE1e",
    "outputId": "52eb4f31-90b6-4cae-c08e-06dc1da9329f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 50, 50, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 50, 50, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 50, 50, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 25, 25, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 25, 25, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_6 (Sequential)    (None, 2)                 132866    \n",
      "=================================================================\n",
      "Total params: 14,847,554\n",
      "Trainable params: 7,211,778\n",
      "Non-trainable params: 7,635,776\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.9626 - accuracy: 0.5965\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.6627 - accuracy: 0.7068\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.5959 - accuracy: 0.7531\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.5243 - accuracy: 0.7807\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4487 - accuracy: 0.8020\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4076 - accuracy: 0.8183\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4095 - accuracy: 0.8133\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3333 - accuracy: 0.8584\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3599 - accuracy: 0.8233\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3790 - accuracy: 0.8446\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3627 - accuracy: 0.8358\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3330 - accuracy: 0.8622\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2685 - accuracy: 0.8922\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2165 - accuracy: 0.9173\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.1969 - accuracy: 0.9173\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2737 - accuracy: 0.8922\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2221 - accuracy: 0.9060\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2380 - accuracy: 0.8972\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2488 - accuracy: 0.8910\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.1889 - accuracy: 0.9311\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4716 - accuracy: 0.8250\n",
      "Test loss: 0.4716168940067291\n",
      "Test accuracy: 0.824999988079071\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model, Sequential\n",
    "from keras import optimizers\n",
    "\n",
    "# ----- データ準備 -----\n",
    "\n",
    "# 画像ファイル名の一覧を取得\n",
    "files_male = os.listdir('./gender_data/male/')\n",
    "files_female = os.listdir('./gender_data/female/')\n",
    "\n",
    "imgs_male = []  # 男性の顔画像リスト\n",
    "imgs_female = []  # 女性の顔画像リスト\n",
    "\n",
    "# 画像を読み込み、学習モデルの入力サイズに変更して、リストに追加\n",
    "for i in range(len(files_male)):\n",
    "    img = cv2.imread('./gender_data/male/' + files_male[i])\n",
    "    img = cv2.resize(img, (50,50))\n",
    "    imgs_male.append(img)\n",
    "\n",
    "for i in range(len(files_female)):\n",
    "    img = cv2.imread('./gender_data/female/' + files_female[i])\n",
    "    img = cv2.resize(img, (50,50))\n",
    "    imgs_female.append(img)\n",
    "\n",
    "# 男女の画像リストを結合し、正解ラベル（0(male), 1(female)）を作成\n",
    "X = np.array(imgs_male + imgs_female)\n",
    "y =  np.array([0] * len(imgs_male) + [1] * len(imgs_female))\n",
    "\n",
    "# 男女それぞれに偏ったindexをランダムに混ぜる\n",
    "random_index = np.random.permutation(np.arange(len(X)))\n",
    "X = X[random_index]\n",
    "y = y[random_index]\n",
    "\n",
    "# データを学習用とテスト用に分割（8対2）\n",
    "X_train = X[:int(len(X)*0.8)]\n",
    "y_train = y[:int(len(y)*0.8)]\n",
    "X_test = X[int(len(X)*0.8):]\n",
    "y_test = y[int(len(y)*0.8):]\n",
    "\n",
    "# 正解ラベルをone-hotベクトル（0(male), 1(female)の2クラス）に変換\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# ----- 予測モデル構築 -----\n",
    "\n",
    "# vgg16モデルのインスタンスを生成\n",
    "input_tensor = Input(shape=(50, 50, 3))\n",
    "vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "# vgg16と連結するモデルを生成\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(BatchNormalization())  # ReLU活性化関数の出力は範囲が限定されないので正規化\n",
    "top_model.add(Dropout(rate=0.5))\n",
    "top_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# モデルの連結\n",
    "model = Model(inputs=vgg16.input, outputs=top_model(vgg16.output))\n",
    "\n",
    "# vgg16の16層目までの重みを固定（最後尾の畳み込み３層の重みは更新）\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# モデルをコンパイル\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              #optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# モデル構成確認\n",
    "model.summary()\n",
    "\n",
    "# ----- モデルの学習と予測評価 -----\n",
    "\n",
    "# 学習\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=20)\n",
    "\n",
    "# モデルをファイルに保存（学習済みモデルとして活用）\n",
    "model.save('model_vgg16.h5', include_optimizer=True)\n",
    "#model.save('model_vgg16_fls.h5', include_optimizer=False)\n",
    "\n",
    "# テストデータによるモデルの精度評価\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "# ----- 検証用 -----\n",
    "\n",
    "# # 男女画像から性別を予測して表示\n",
    "# gender = None\n",
    "# for i in range(5):\n",
    "#     img = cv2.imread('./gender_data/male/' + files_male[i])\n",
    "#     #img = cv2.imread('./gender_data/female/' + files_female[i])  # 女性でテスト\n",
    "\n",
    "#     # cv2のimread()で読み込んだデータは色指定順がBGRとなっているのでRGBに変更\n",
    "#     b, g, r = cv2.split(img) \n",
    "#     img = cv2.merge((r, g, b))\n",
    "\n",
    "#     # 画像を表示\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    \n",
    "#     # 画像サイズをモデルの入力サイズに変更する\n",
    "#     img = cv2.resize(img, (50, 50))\n",
    "\n",
    "#     # 画像をモデルの入力Shapeに合わるため、４次元ndarrayに変換：（行番, width, hight, rgb)\n",
    "#     img_reshape = img.reshape((-1, 50, 50, 3))\n",
    "\n",
    "#     # 性別を予測：0(male), 1(female)\n",
    "#     pred = np.argmax(model.predict(img_reshape))\n",
    "#     #pred = np.argmax(model.predict(np.array([face_img])), axis=1)\n",
    "#     if pred == 0:\n",
    "#         gender =  'male'\n",
    "#     else:\n",
    "#         gender = 'female'\n",
    "\n",
    "#     print(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-MvLp5nQNJzL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNBhNxH0RFTflYMAT3CKC6A",
   "collapsed_sections": [],
   "mount_file_id": "1fCWTPHXRcRKNLDoa2BXEVInYAbxCqgx4",
   "name": "gender_recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
